{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SahithReddy-GitHub/Speech-Emotion-Recognition-Using-Deep-Learning/blob/main/SSP_PROJECT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6eJFqFEqLiA"
      },
      "source": [
        "\n",
        "Model:- MLP Classifier<br>\n",
        "Dataset :- RAVDESS<br>\n",
        "Data:- 1440 <br>\n",
        "Train_Data :- 1080 <br>\n",
        "Test_Data :- 360<br>\n",
        "File Type:- .wav <br>\n",
        "Emotions :- neutral,calm,happy,sad,angry,fearful,disgust,surprise<br>\n",
        "Accuracy :- 86.7%\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YRkxEfc3nuck",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccb474ec-3b37-4223-b14c-c018a716bdfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.8/dist-packages (0.8.1)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.8/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyaudio\n",
            "  Downloading PyAudio-0.2.13.tar.gz (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.4.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.2.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.7.3)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile) (2.21)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (6.0.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (2.25.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (4.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.43.0->librosa) (3.11.0)\n",
            "Building wheels for collected packages: sklearn, pyaudio\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=bf76f8e34009f5b6a82777da783bd293e926faff1f70d3b5891313e2ff5c22ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pyaudio \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for pyaudio\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully built sklearn\n",
            "Failed to build pyaudio\n",
            "\u001b[31mERROR: Could not build wheels for pyaudio, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install librosa soundfile numpy sklearn pyaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-2_QfKNonu9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf8ad2e8-6675-45e9-a20e-9bc4250f3859"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.8/dist-packages (0.11.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile) (2.21)\n"
          ]
        }
      ],
      "source": [
        "!pip install soundfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eVdfWZwanvWk"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import soundfile\n",
        "import os, glob, pickle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AB85rJMLowEc"
      },
      "outputs": [],
      "source": [
        "def extract_feature(file_name, mfcc, chroma, mel):\n",
        "  X, sample_rate= librosa.load(os.path.join(file_name), res_type='kaiser_fast')\n",
        "  if chroma:\n",
        "    stft= np.abs(librosa.stft(X))\n",
        "  result=np.array([])\n",
        "  if mfcc:\n",
        "    mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "    result=np.hstack((result, mfccs))\n",
        "  if chroma:\n",
        "    chroma =np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "    result=np.hstack((result, chroma))\n",
        "  if mel:\n",
        "    mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "    result=np.hstack((result, mel))\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3c9G5Y_ypHRD"
      },
      "outputs": [],
      "source": [
        "# Emotions in the RAVDESS & TESS dataset\n",
        "emotions={\n",
        "  '01':'neutral',\n",
        "  '02':'calm',\n",
        "  '03':'happy',\n",
        "  '04':'sad',\n",
        "  '05':'angry',\n",
        "  '06':'fearful',\n",
        "  '07':'disgust',\n",
        "  '08':'surprised'\n",
        "}\n",
        "# Emotions to observe\n",
        "observed_emotions=['neutral','calm','happy','sad','angry','fearful', 'disgust','surprised']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IPuPQdvorWPF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e77f5d47-9de9-4647-895d-8067c603ae80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:12: SyntaxWarning: 'int' object is not callable; perhaps you missed a comma?\n",
            "<>:12: SyntaxWarning: 'int' object is not callable; perhaps you missed a comma?\n",
            "<ipython-input-6-1fde5415dd73>:12: SyntaxWarning: 'int' object is not callable; perhaps you missed a comma?\n",
            "  content/drive/MyDrive/SSP_PROJECT_DATASET/audio_speech_actors_01-24()\n"
          ]
        }
      ],
      "source": [
        "def load_data(test_size=0.2):\n",
        "  x,y=[],[]\n",
        "  for file in glob.glob('/content/drive/MyDrive/SSP_PROJECT_DATASET/Actor_23/*.wav'):\n",
        "    file_name=os.path.basename(file)\n",
        "    emotion=emotions[file_name.split(\"-\")[2]]\n",
        "    if emotion not in observed_emotions:\n",
        "      continue\n",
        "    feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
        "    x.append(feature)\n",
        "    y.append(emotion)\n",
        "  return train_test_split(np.array(x), y, test_size=test_size, train_size= 0.75,random_state=9)\n",
        "  /content/drive/MyDrive/SSP_PROJECT_DATASET/audio_speech_actors_01-24\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "I0XXPV0QS1B2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b28b102d-629f-4b9e-9e85-505487771e1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "h78BjGKHvpF7"
      },
      "outputs": [],
      "source": [
        "#split the dataset\n",
        "import time\n",
        "x_train,x_test,y_train,y_test=load_data(test_size=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5v9vojtyuhD",
        "outputId": "02d3bbbf-f74a-416a-f116-430ad4b6d000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(45, 15)\n"
          ]
        }
      ],
      "source": [
        "#Get the shape of training and testing datasets\n",
        "print((x_train.shape[0],x_test.shape[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_haFMlqzBDa",
        "outputId": "efc1082a-7d7a-410a-9cc6-7dfdf73c6485"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features extracted: 180\n"
          ]
        }
      ],
      "source": [
        "#Get the number of Features extracted\n",
        "print(f'Features extracted: {x_train.shape[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YnyqbF0rzZop"
      },
      "outputs": [],
      "source": [
        "# Initialize the Multi Layer Perceptron Classifier\n",
        "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive' , max_iter=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rjWudHXgzb8n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67b0f63f-8edc-4a2c-d39b-3469b6f00e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:611: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(alpha=0.01, batch_size=256, hidden_layer_sizes=(300,),\n",
              "              learning_rate='adaptive', max_iter=500)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#Train the model\n",
        "model.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7D2B9K8Dz_n4"
      },
      "outputs": [],
      "source": [
        "#Predict for the test set\n",
        "y_pred=model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xfcmonY0JYx",
        "outputId": "dc729070-fb42-4228-b6cd-dc87494ff0eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 86.67%\n"
          ]
        }
      ],
      "source": [
        "# Calculate the accuracy of our model\n",
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "#Print the accuracy\n",
        "print(\"Accuracy: {:.2f}%\" .format(accuracy*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apb5UbDg0bvA",
        "outputId": "930698af-7562-41db-ced7-7004ecb594de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      0.75      0.86         4\n",
            "        calm       1.00      1.00      1.00         2\n",
            "     fearful       1.00      0.67      0.80         3\n",
            "       happy       0.50      1.00      0.67         2\n",
            "         sad       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.87        15\n",
            "   macro avg       0.90      0.88      0.86        15\n",
            "weighted avg       0.93      0.87      0.88        15\n",
            "\n"
          ]
        }
      ],
      "source": [
        "##############      CLASSIFICATION REPORT       #####################\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "55cpBit91RNf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "119e7e23-5808-4b60-a9ea-41808ad474e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3 0 0 1 0]\n",
            " [0 2 0 0 0]\n",
            " [0 0 2 1 0]\n",
            " [0 0 0 2 0]\n",
            " [0 0 0 0 4]]\n"
          ]
        }
      ],
      "source": [
        "#CONFUSION MATRIX\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "matrix = confusion_matrix(y_test,y_pred)\n",
        "print (matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HHEi7v--rVze"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1SMUEHS9lF51o_vFX5CtDF-g02Ja6R5s6",
      "authorship_tag": "ABX9TyP3vh+GWCJT2VIdxrFjEyn0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}