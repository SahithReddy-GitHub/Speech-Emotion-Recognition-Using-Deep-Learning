# Speech-Emotion-Recognition-Using-Deep-Learning



The aim of this project is to develop a model that can detect the emotions elicited by a speaker while they are talking. Emotions such as fear, anger, or joy are often characterized by loud and fast speech with a higher and wider range in pitch. On the other hand, emotions such as sadness or tiredness tend to generate slow and low-pitched speech. The ability to detect human emotions through voice and speech patterns has many potential applications, such as improving human-machine interactions.

To accomplish this goal, we propose a classification model of emotions elicited by speech based on deep neural networks, specifically CNNs, SVM, and MLP Classifier. The model is trained to classify eight different emotions: neutral, calm, happy, sad, angry, fearful, disgust, and surprise. We use acoustic features such as Mel Frequency Cepstral Coefficient (MFCC) as inputs to the model.

We evaluate our model using the Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) dataset and the Toronto Emotional Speech Set (TESS) dataset. Our results show that the proposed approach yields high accuracy levels of 86%, 84%, and 82% using CNN, MLP Classifier and SVM Classifiers respectively for 8 emotions.

Detection of human emotions through voice-pattern and speech-pattern analysis has many applications, one of which is to improve human-machine interactions. This technology can be used in various fields such as virtual assistants, customer service, and affective computing. By detecting the emotions of a speaker, a machine can respond in a more appropriate and natural way, thus providing a better user experience. Additionally, it can be used in healthcare, education, and other fields where the ability to understand and respond to emotions is crucial. The ability to detect emotions through speech and voice patterns can also be used to improve the accuracy of speech recognition systems, natural language processing, and other areas of artificial intelligence.




RAVDESS DATASET DRIVE LINK  ==>  https://drive.google.com/drive/folders/1-_B_P2E-B-KkESRJvGc5azTHijDzaldb?usp=sharing

GOOGLE COLAB LINK  ==>  

